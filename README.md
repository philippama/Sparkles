This is my Spark playground, the [Apache Spark](http://spark.apache.org/) for data processing, not the web application framework one. It contains several projects because I want to keep them all in one place. They run on a Spark 1.5.0 package pre-built for Hadoop 2.6, downloaded from http://spark.apache.org/downloads.html. The README.md that comes in the Spark package has useful information on how to run the Spark Scala and Python shells, the example programs and tests.

To run the Spark Scala shell, if SPARK_HOME is set to the Spark installation directory:
```
$SPARK_HOME/bin/spark-shell
```
